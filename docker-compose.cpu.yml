services:
  gptoss:
    image: vllm/vllm-openai:latest
    ports:
      - "8003:8000"
    volumes:
      - gptoss_workspace:/workspace
    command: >
      python -m vllm.entrypoints.openai.api_server
      --model ${MODEL}
      --device cpu
      --host 0.0.0.0 --port 8000
    environment:
      VLLM_TARGET_DEVICE: cpu
      VLLM_LOGGING_LEVEL: DEBUG
      MODEL: ${MODEL:-openai/gpt-oss-20b}
      CUDA_VISIBLE_DEVICES: ""
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/health"]
      interval: 5s
      timeout: 2s
      retries: 12
      start_period: 5s
    networks:
      - gptoss_net

  gptoss_check:
    environment:
      VLLM_TARGET_DEVICE: cpu

networks:
  gptoss_net:
    name: gptoss_net
    driver: bridge

volumes:
  gptoss_workspace:
