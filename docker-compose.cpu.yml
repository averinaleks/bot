services:
  gptoss:
    ports:
      - "8003:8000"
    volumes:
      - gptoss_workspace:/workspace
    command: >
      python -m vllm.entrypoints.openai.api_server --host 0.0.0.0 --port 8000 --model ${MODEL_ID:-TinyLlama/TinyLlama-1.1B-Chat-v1.0} --device cpu --dtype float32 --disable_async_output_proc
    environment:
      - VLLM_DEVICE=cpu
      - VLLM_LOGGING_LEVEL=DEBUG
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/health"]
      interval: 5s
      timeout: 2s
      retries: 12
      start_period: 5s
    networks:
      - gptoss_net

  gptoss_check:
    environment:
      VLLM_TARGET_DEVICE: cpu

networks:
  gptoss_net:
    name: gptoss_net
    driver: bridge

volumes:
  gptoss_workspace:
