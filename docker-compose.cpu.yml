services:
  gptoss:
    build:
      context: .
      dockerfile: ${DOCKERFILE:-Dockerfile.cpu}
    command: >
      python -m vllm.entrypoints.openai.api_server
        --model "${MODEL}" --device cpu --host 0.0.0.0 --port 8000
    environment:
      VLLM_LOGGING_LEVEL: DEBUG
      MODEL: ${MODEL}
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 60
      start_period: 120s
