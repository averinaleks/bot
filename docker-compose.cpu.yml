services:
  gptoss:
    build:
      context: .
      dockerfile: Dockerfile.gptoss
    command: python3 -m vllm.entrypoints.openai.api_server --host 0.0.0.0 --port 8000 --model ${MODEL:-openai/gpt-oss-20b} --device cpu --max-num-seqs 4 --enforce-eager --disable-async-output-proc
    ports:
      - "8003:8000"
    volumes:
      - gptoss_workspace:/workspace
    environment:
      VLLM_LOGGING_LEVEL: DEBUG
      MODEL: ${MODEL:-openai/gpt-oss-20b}
      CUDA_VISIBLE_DEVICES: ""
      VLLM_TARGET_DEVICE: cpu
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/health"]
      interval: 5s
      timeout: 2s
      retries: 12
      start_period: 5s
    networks:
      - gptoss_net

networks:
  gptoss_net:
    name: gptoss_net
    driver: bridge

volumes:
  gptoss_workspace:
