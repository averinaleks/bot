# .github/workflows/gptoss_review.yml
# yamllint disable rule:line-length
name: GPT-OSS Code Review

on:
  pull_request_target:
    types: [opened, synchronize, reopened, ready_for_review]
  issue_comment:
    types: [created]

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  review:
    # Защита: не запускаем на fork без метки "safe-to-test"
    if: >-
      ((github.event_name == 'pull_request_target') &&
       (github.event.pull_request != null) &&
       (github.event.pull_request.draft == false) &&
       (github.event.pull_request.head.repo.full_name == github.repository ||
        contains(github.event.pull_request.labels.*.name, 'safe-to-test')))
      || (github.event_name == 'issue_comment' &&
          github.event.issue != null &&
          github.event.issue.pull_request != null &&
          github.event.comment != null &&
          contains(github.event.comment.body || '', '/llm-review'))
    runs-on: ubuntu-latest
    timeout-minutes: 25
    env:
      PR_NUMBER: ${{ github.event.pull_request.number || github.event.issue.number }}
      MODEL_NAME: ${{ vars.LLM_MODEL || 'Qwen/Qwen2.5-Coder-1.5B-Instruct' }}
      HF_TOKEN: ${{ secrets.HF_TOKEN || '' }}

    steps:
      - uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0
        with:
          fetch-depth: 0
          ref: refs/pull/${{ env.PR_NUMBER }}/head

      - name: Start vLLM container (isolated)
        run: |
          set -euo pipefail
          docker run -d --rm --name gptoss \
            --network none \
            -e HUGGING_FACE_HUB_TOKEN="$HF_TOKEN" \
            -p 127.0.0.1:8000:8000 \
            vllm/vllm-openai:v0.10.1 \
            --model "${MODEL_NAME}" \
            --trust-remote-code \
            --device cpu

      - name: Wait for LLM container (with backoff)
        id: wait_llm
        run: |
          set -euo pipefail
          for i in $(seq 1 60); do
            if docker ps --filter "name=gptoss" --filter "status=running" | grep -q gptoss; then
              if curl -sS --max-time 2 http://127.0.0.1:8000/v1/models > /dev/null; then
                echo "ok=1" >> "$GITHUB_OUTPUT"
                exit 0
              fi
            else
              echo "LLM container exited"
              docker logs gptoss || true
              exit 1
            fi
            sleep 5
          done
          echo "LLM container failed to become ready"
          docker logs gptoss || true
          exit 1

      - name: Install tools
        if: steps.wait_llm.outputs.ok == '1'
        run: |
          sudo apt-get update
          sudo apt-get install -y jq moreutils

      - name: Generate Python diff
        id: gen_diff
        if: steps.wait_llm.outputs.ok == '1'
        env:
          GITHUB_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail
          pull_info=$(curl -sS -H "Authorization: token $GITHUB_TOKEN" \
            "https://api.github.com/repos/${{ github.repository }}/pulls/${PR_NUMBER}")
          base_sha=$(jq -r .base.sha <<<"$pull_info")
          base_ref=$(jq -r .base.ref <<<"$pull_info")
          test -n "$base_sha" && test -n "$base_ref"
          git fetch --no-tags origin "$base_ref"
          git diff "$base_sha"...HEAD -- ':(glob)**/*.py' > diff.patch || true
          head -c 180000 diff.patch > diff.patch   # truncate
          tokens=$(wc -w < diff.patch || echo 0)
          if [ "$tokens" -eq 0 ]; then
            printf 'has_diff=false\n' >> "$GITHUB_OUTPUT"; exit 0
          fi
          if [ "$tokens" -gt 6000 ]; then
            git diff -U20 "$base_sha"...HEAD -- ':(glob)**/*.py' > diff.patch || true
            head -c 180000 diff.patch > diff.patch
          fi
          if [ ! -s diff.patch ]; then
            printf 'has_diff=false\n' >> "$GITHUB_OUTPUT"; exit 0
          fi
          split -b 90000 -a 2 diff.patch part_ || true
          printf 'has_diff=true\n' >> "$GITHUB_OUTPUT"

      - name: LLM review
        id: llm_review
        if: steps.gen_diff.outputs.has_diff == 'true'
        run: |
          set -euo pipefail
          review_file="review.md"
          : > "$review_file"
          if ls part_* >/dev/null 2>&1; then
            for p in part_*; do
              payload=$(jq -nc --arg d "$(cat "$p")" --arg m "$MODEL_NAME" \
                '{model:$m, messages:[{role:"user", content:"Review the following diff and provide actionable feedback:\n" + $d}], temperature:0}')
              resp=$(curl -sS --max-time 30 -H "Content-Type: application/json" \
                -d "$payload" http://127.0.0.1:8000/v1/chat/completions || true)
              echo "${resp}" | jq -r '.choices[0].message.content // empty' >> "$review_file"
              echo -e "\n---\n" >> "$review_file"
            done
          else
            payload=$(jq -nc --arg d "$(cat diff.patch)" --arg m "$MODEL_NAME" \
              '{model:$m, messages:[{role:"user", content:"Review the following diff and provide actionable feedback:\n" + $d}], temperature:0}')
            resp=$(curl -sS --max-time 30 -H "Content-Type: application/json" \
              -d "$payload" http://127.0.0.1:8000/v1/chat/completions || true)
            echo "${resp}" | jq -r '.choices[0].message.content // empty' > "$review_file"
          fi
          if [ ! -s "$review_file" ]; then
            echo "no content from LLM" | sponge "$review_file"
            echo "has_content=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          echo "has_content=true" >> "$GITHUB_OUTPUT"

      - name: Comment PR
        if: steps.llm_review.outputs.has_content == 'true'
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            const fs = require('fs');
            const body = fs.readFileSync('review.md', 'utf8').slice(0, 60000);
            const pr = parseInt(process.env.PR_NUMBER, 10);
            await github.rest.issues.createComment({ owner: context.repo.owner, repo: context.repo.repo, issue_number: pr, body });

      - name: Cleanup
        if: always()
        run: docker rm -f gptoss || true
