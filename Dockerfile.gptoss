FROM python:3.12-slim

# Исправляем отсутствие libtbbmalloc.so.2, устанавливаем свежие патчи и ставим curl для health-check’а
# Дополнительно устанавливаем инструменты сборки и git для сборки vLLM
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential git cmake ninja-build \
    libtbbmalloc2=2022.1.0-1 curl=8.14.1-2 \
    && rm -rf /var/lib/apt/lists/*

ENV PYTHONUNBUFFERED=1 HF_HOME=/workspace/hf-cache
ENV VLLM_TARGET_DEVICE=cpu
ENV PIP_EXTRA_INDEX_URL=https://download.pytorch.org/whl/cpu
RUN pip install --no-cache-dir --upgrade pip && \
    git clone --depth=1 https://github.com/vllm-project/vllm.git /tmp/vllm && \
    cd /tmp/vllm && \
    pip install --no-cache-dir -r requirements-cpu.txt && \
    VLLM_TARGET_DEVICE=cpu python setup.py install && \
    rm -rf /tmp/vllm

EXPOSE 8000

CMD python -m vllm.entrypoints.openai.api_server --host 0.0.0.0 --port 8000 --model ${MODEL:-openai/gpt-oss-20b} --device cpu --max-num-seqs 4 --enforce-eager --disable-async-output-proc
